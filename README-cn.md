<div align="center">
<img src="./assets/minicpm_logo.png" width="500em" ></img> 
</div>

<h4 align="center">
    <p>
        <b>ä¸­æ–‡</b> | <a href="https://github.com/OpenBMB/MiniCPM/blob/main/README.md">English</a>
    <p>
</h4>


<p align="center">
<a href="https://arxiv.org/pdf/2506.07900" target="_blank">MiniCPM è®ºæ–‡</a> |
<a href="https://modelbest.feishu.cn/wiki/D2tFw8Pcsi5CIzkaHNacLK64npg" target="_blank">MiniCPM çŸ¥è¯†åº“</a> |
<a href="https://github.com/OpenBMB/MiniCPM-V/" target="_blank">MiniCPM-V ä»“åº“</a> |
åŠ å…¥æˆ‘ä»¬çš„ <a href="https://discord.gg/3cGQn9b3YM" target="_blank">discord</a> å’Œ <a href="https://github.com/OpenBMB/MiniCPM/blob/main/assets/wechat.jpg" target="_blank">å¾®ä¿¡ç¾¤</a> |
<a href="https://mp.weixin.qq.com/s/KIhH2nCURBXuFXAtYRpuXg?poc_token=HBIsUWijxino8oJ5s6HcjcfXFRi0Xj2LJlxPYD9c">åŠ å…¥æˆ‘ä»¬</a>
</p>

## æ›´æ–°æ—¥å¿—ğŸ”¥
- [2026.02.11] **[MiniCPM-SALA](https://huggingface.co/openbmb/MiniCPM-SALA)** å‘å¸ƒï¼è¿™æ˜¯é¦–ä¸ªç»è¿‡å¤§è§„æ¨¡å®éªŒéªŒè¯çš„ç¨€ç–ä¸çº¿æ€§æ··åˆæ³¨æ„åŠ›æ¨¡å‹ï¼Œæ”¯æŒç™¾ä¸‡è¯å…ƒçš„æœ‰æ•ˆå¤„ç†ä¸é«˜æ•ˆæ¨ç†ã€‚ğŸ”¥ğŸ”¥ğŸ”¥
- [2025.09.29] **å‘å¸ƒ [InfLLM-V2è¯¦ç»†æŠ€æœ¯è®ºæ–‡](https://arxiv.org/abs/2509.24663)!**ä»…éœ€5Bé•¿æ–‡æœ¬è¯å…ƒï¼Œå³å¯å®Œæˆç¨€ç–æ³¨æ„åŠ›èƒ½åŠ›çš„è®­ç»ƒğŸ”¥ğŸ”¥ğŸ”¥
- [2025.09.05] **å‘å¸ƒ [MiniCPM4.1](https://huggingface.co/collections/openbmb/minicpm-4-6841ab29d180257e940baa9b)ï¼è¯¥æ¨¡å‹åŸºäºåŸç”Ÿç¨€ç–æ³¨æ„åŠ›æ¶æ„ï¼ˆInfLLM-V2ï¼‰ï¼Œæ”¯æŒæ··åˆæ€è€ƒã€‚ğŸ”¥ğŸ”¥ğŸ”¥**
- [2025.06.06] å‘å¸ƒ [MiniCPM4](https://huggingface.co/collections/openbmb/minicpm-4-6841ab29d180257e940baa9b)ï¼è¯¥æ¨¡å‹åœ¨ä¿æŒåŒç­‰è§„æ¨¡æœ€ä¼˜æ€§èƒ½çš„åŒæ—¶ï¼Œå®ç°äº†æè‡´çš„æ•ˆç‡æå‡ï¼åœ¨å…¸å‹ç«¯ä¾§èŠ¯ç‰‡ä¸Šèƒ½å¤Ÿå®ç° 5 å€ä»¥ä¸Šç”ŸæˆåŠ é€Ÿï¼
- [2024.09.05] å‘å¸ƒ [MiniCPM3-4B](https://huggingface.co/openbmb/MiniCPM3-4B)ï¼è¯¥æ¨¡å‹çš„è¡¨ç°è¶…è¶Š Phi-3.5-mini-instruct å’Œ GPT-3.5-Turbo-0125ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ¯”è‚© Llama3.1-8B-Instructã€Qwen2-7B-Instructã€GLM-4-9B-Chat ç­‰å¤šä¸ª 7B-9B å‚æ•°é‡çš„æ¨¡å‹ã€‚
- [2024.07.05] å‘å¸ƒ [MiniCPM-S-1B](https://huggingface.co/openbmb/MiniCPM-S-1B-sft)ï¼è¯¥æ¨¡å‹åœ¨ä¿æŒä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½æ— æŸçš„å‰æä¸‹ï¼ŒFFN å±‚å®ç°äº† 87.89% çš„å¹³å‡ç¨€ç–åº¦ï¼Œå°† FFN FLOPs é™ä½äº† 84%ã€‚
- [2024.04.11] å‘å¸ƒ [MiniCPM-2B-128k](https://huggingface.co/openbmb/MiniCPM-2B-128k)ã€[MiniCPM-MoE-8x2B](https://huggingface.co/openbmb/MiniCPM-MoE-8x2B) å’Œ [MiniCPM-1B](https://huggingface.co/openbmb/MiniCPM-1B-sft-bf16)ï¼ç‚¹å‡»[è¿™é‡Œ](https://openbmb.vercel.app/?category=Chinese+Blog)æŸ¥çœ‹æŠ€æœ¯åšå®¢ã€‚
- [2024.02.01] å‘å¸ƒ [MiniCPM-2B](https://huggingface.co/openbmb/MiniCPM-2B-sft-bf16)ï¼è¯¥æ¨¡å‹åœ¨å…¬å¼€è¯„æµ‹é›†ä¸Šä¸ Mistral-7B è¡¨ç°ç›¸è¿‘ï¼ˆä¸­æ–‡ã€æ•°å­¦ã€ä»£ç èƒ½åŠ›æ›´ä¼˜ï¼‰ï¼Œæ•´ä½“æ€§èƒ½è¶…è¶Š Llama2-13Bã€MPT-30Bã€Falcon-40B ç­‰æ¨¡å‹ã€‚

## ç›®å½•

- [æ›´æ–°æ—¥å¿—ğŸ”¥](#æ›´æ–°æ—¥å¿—)
- [ç›®å½•](#ç›®å½•)
- [æ¨¡å‹ä¸‹è½½](#æ¨¡å‹ä¸‹è½½)
- [MiniCPM-SALA](#minicpm-sala)
- [MiniCPM4 å’Œ MiniCPM4.1 ç³»åˆ—](#minicpm4-å’Œ-minicpm41-ç³»åˆ—)
    - [äº®ç‚¹](#äº®ç‚¹)
    - [ç®€ä»‹](#ç®€ä»‹)
  - [è¯„æµ‹ç»“æœ](#è¯„æµ‹ç»“æœ)
    - [æ•ˆç‡è¯„æµ‹](#æ•ˆç‡è¯„æµ‹)
    - [ç»¼åˆè¯„æµ‹](#ç»¼åˆè¯„æµ‹)
    - [é•¿æ–‡æœ¬è¯„æµ‹](#é•¿æ–‡æœ¬è¯„æµ‹)
  - [æ¨¡å‹æ¨ç†](#æ¨¡å‹æ¨ç†)
    - [æ··åˆæ€è€ƒ](#æ··åˆæ€è€ƒ)
    - [HuggingFace](#huggingface)
    - [vLLM](#vllm)
      - [æŠ•æœºé‡‡æ ·](#æŠ•æœºé‡‡æ ·)
        - [1. ä¸‹è½½ MiniCPM4.1 è‰ç¨¿æ¨¡å‹](#1-ä¸‹è½½-minicpm41-è‰ç¨¿æ¨¡å‹)
        - [2. å®‰è£… EAGLE3 å…¼å®¹çš„ vLLM](#2-å®‰è£…-eagle3-å…¼å®¹çš„-vllm)
        - [3. å¯åŠ¨å¸¦æœ‰æŠ•æœºé‡‡æ ·çš„ vLLM æœåŠ¡](#3-å¯åŠ¨å¸¦æœ‰æŠ•æœºé‡‡æ ·çš„-vllm-æœåŠ¡)
        - [4. å®¢æˆ·ç«¯ä½¿ç”¨ç¤ºä¾‹](#4-å®¢æˆ·ç«¯ä½¿ç”¨ç¤ºä¾‹)
        - [vLLM é…ç½®å‚æ•°è¯´æ˜](#vllm-é…ç½®å‚æ•°è¯´æ˜)
      - [æ ‡å‡†æ¨ç†ï¼ˆä¸ä½¿ç”¨æŠ•æœºé‡‡æ ·ï¼‰](#æ ‡å‡†æ¨ç†ä¸ä½¿ç”¨æŠ•æœºé‡‡æ ·)
    - [SGLang](#sglang)
      - [æŠ•æœºé‡‡æ ·](#æŠ•æœºé‡‡æ ·-1)
        - [1. ä¸‹è½½ MiniCPM4.1 è‰ç¨¿æ¨¡å‹](#1-ä¸‹è½½-minicpm41-è‰ç¨¿æ¨¡å‹-1)
        - [2. å®‰è£… EAGLE3 å…¼å®¹çš„ SGLang](#2-å®‰è£…-eagle3-å…¼å®¹çš„-sglang)
        - [3. å¯åŠ¨å¸¦æœ‰æŠ•æœºé‡‡æ ·çš„ SGLang æœåŠ¡](#3-å¯åŠ¨å¸¦æœ‰æŠ•æœºé‡‡æ ·çš„-sglang-æœåŠ¡)
        - [4. å®¢æˆ·ç«¯ä½¿ç”¨](#4-å®¢æˆ·ç«¯ä½¿ç”¨)
        - [é…ç½®å‚æ•°è¯´æ˜](#é…ç½®å‚æ•°è¯´æ˜)
      - [æ ‡å‡†æ¨ç†ï¼ˆä¸ä½¿ç”¨æŠ•æœºé‡‡æ ·ï¼‰](#æ ‡å‡†æ¨ç†ä¸ä½¿ç”¨æŠ•æœºé‡‡æ ·-1)
    - [CPM.cu](#cpmcu)
    - [llama.cpp and Ollama](#llamacpp-and-ollama)
    - [llama.cpp](#llamacpp)
    - [Ollama](#ollama)
  - [æ¨¡å‹å¾®è°ƒ](#æ¨¡å‹å¾®è°ƒ)
    - [LLaMA-Factory](#llama-factory)
  - [BitCPM4: æ¨¡å‹é‡åŒ–](#bitcpm4-æ¨¡å‹é‡åŒ–)
    - [BitCPM4 è¯„æµ‹](#bitcpm4-è¯„æµ‹)
    - [BitCPM4 æ¨¡å‹æ¨ç†](#bitcpm4-æ¨¡å‹æ¨ç†)
  - [æ¨¡å‹åº”ç”¨](#æ¨¡å‹åº”ç”¨)
    - [MiniCPM4-Survey: ç»¼è¿°ç”Ÿæˆ](#minicpm4-survey-ç»¼è¿°ç”Ÿæˆ)
      - [ä½¿ç”¨ä¸æ¼”ç¤ºæ¡ˆä¾‹](#ä½¿ç”¨ä¸æ¼”ç¤ºæ¡ˆä¾‹)
      - [è¯„ä¼°](#è¯„ä¼°)
    - [MiniCPM4-MCP: MCPå¢å¼ºçš„å·¥å…·è°ƒç”¨](#minicpm4-mcp-mcpå¢å¼ºçš„å·¥å…·è°ƒç”¨)
      - [ä½¿ç”¨ä¸æ¼”ç¤ºæ¡ˆä¾‹](#ä½¿ç”¨ä¸æ¼”ç¤ºæ¡ˆä¾‹-1)
      - [è¯„ä¼°](#è¯„ä¼°-1)
    - [MiniCPM Intel AIPC Client: ç«¯ä¾§å¤§æ¨¡å‹å®¢æˆ·ç«¯](#minicpm-intel-aipc-client-ç«¯ä¾§å¤§æ¨¡å‹å®¢æˆ·ç«¯)
- [å¼€æºåè®®](#å¼€æºåè®®)
    - [æ¨¡å‹åè®®](#æ¨¡å‹åè®®)
    - [å£°æ˜](#å£°æ˜)
- [å¼€å‘æœºæ„](#å¼€å‘æœºæ„)
- [å·¥ä½œå¼•ç”¨](#å·¥ä½œå¼•ç”¨)


## æ¨¡å‹ä¸‹è½½

  | HuggingFace | ModelScope |
  |-------------|------------|
  | [MiniCPM-SALA](https://huggingface.co/openbmb/MiniCPM-SALA) | [MiniCPM-SALA](https://www.modelscope.cn/models/OpenBMB/MiniCPM-SALA) |
  | [MiniCPM4.1-8B](https://huggingface.co/openbmb/MiniCPM4.1-8B) | [MiniCPM4.1-8B](https://www.modelscope.cn/models/OpenBMB/MiniCPM4.1-8B) |
  | [MiniCPM4.1-8B-GPTQ](https://huggingface.co/openbmb/MiniCPM4.1-8B-GPTQ) | [MiniCPM4.1-8B-GPTQ](https://www.modelscope.cn/openbmb/MiniCPM4.1-8B-GPTQ) | 
  | [MiniCPM4.1-8B-AutoAWQ](https://huggingface.co/openbmb/MiniCPM4.1-8B-AutoAWQ) | [MiniCPM4.1-8B-AutoAWQ](https://www.modelscope.cn/openbmb/MiniCPM4.1-8B-AutoAWQ) | 
  | [MiniCPM-4.1-8B-Marlin](https://huggingface.co/openbmb/MiniCPM-4.1-8B-Marlin) | [MiniCPM-4.1-8B-Marlin](https://www.modelscope.cn/openbmb/MiniCPM-4.1-8B-Marlin) | 
  | [MiniCPM4.1-8B-GGUF](https://huggingface.co/openbmb/MiniCPM4.1-8B-GGUF) | [MiniCPM4.1-8B-GGUF](https://www.modelscope.cn/openbmb/MiniCPM4.1-8B-GGUF) | 
  | [MiniCPM4.1-8B-MLX](https://huggingface.co/openbmb/MiniCPM4.1-8B-MLX) | [MiniCPM4.1-8B-MLX](https://www.modelscope.cn/openbmb/MiniCPM4.1-8B-MLX) | 
  | [MiniCPM4.1-8B-Eagle3](https://huggingface.co/openbmb/MiniCPM4.1-8B-Eagle3) | [MiniCPM4.1-8B-Eagle3](https://www.modelscope.cn/openbmb/MiniCPM4.1-8B-Eagle3) | 
  | [MiniCPM4-8B](https://huggingface.co/openbmb/MiniCPM4-8B)    | [MiniCPM4-8B](https://www.modelscope.cn/models/OpenBMB/MiniCPM4-8B) |
  | [MiniCPM4-0.5B](https://huggingface.co/openbmb/MiniCPM4-0.5B) | [MiniCPM4-0.5B](https://www.modelscope.cn/models/OpenBMB/MiniCPM4-0.5B) |
  | [BitCPM4-1B](https://huggingface.co/openbmb/BitCPM4-1B)        | [BitCPM4-1B](https://www.modelscope.cn/models/OpenBMB/BitCPM4-1B) |
  | [BitCPM4-0.5B](https://huggingface.co/openbmb/BitCPM4-0.5B)    | [BitCPM4-0.5B](https://www.modelscope.cn/models/OpenBMB/BitCPM4-0.5B) |
  | [MiniCPM4-Survey](https://huggingface.co/openbmb/MiniCPM4-Survey) | [MiniCPM4-Survey](https://www.modelscope.cn/models/OpenBMB/MiniCPM4-Survey) |
  | [MiniCPM4-MCP](https://huggingface.co/openbmb/MiniCPM4-MCP)  | [MiniCPM4-MCP](https://www.modelscope.cn/models/OpenBMB/MiniCPM4-MCP) |


<details>
<summary>ğŸ“‹ ç‚¹å‡»å±•å¼€æŸ¥çœ‹æ‰€æœ‰ MiniCPM ç³»åˆ—æ¨¡å‹</summary>

  | HuggingFace | ModelScope |
  |-------------|------------|
  | [MiniCPM4-8B-Eagle-FRSpec](https://huggingface.co/openbmb/MiniCPM4-8B-Eagle-FRSpec) | [MiniCPM4-8B-Eagle-FRSpec](https://www.modelscope.cn/models/OpenBMB/MiniCPM4-8B-Eagle-FRSpec) |
  | [MiniCPM4-8B-Eagle-FRSpec-QAT](https://huggingface.co/openbmb/MiniCPM4-8B-Eagle-FRSpec-QAT) | [MiniCPM4-8B-Eagle-FRSpec-QAT](https://www.modelscope.cn/models/OpenBMB/MiniCPM4-8B-Eagle-FRSpec-QAT) |
  | [MiniCPM4-8B-Eagle-vLLM](https://huggingface.co/openbmb/MiniCPM4-8B-Eagle-vLLM) | [MiniCPM4-8B-Eagle-vLLM](https://www.modelscope.cn/models/OpenBMB/MiniCPM4-8B-Eagle-vLLM) |
  | [MiniCPM4-8B-marlin-Eagle-vLLM](https://huggingface.co/openbmb/MiniCPM4-8B-marlin-Eagle-vLLM) | [MiniCPM4-8B-marlin-Eagle-vLLM](https://www.modelscope.cn/models/OpenBMB/MiniCPM4-8B-marlin-Eagle-vLLM) |
  | [MiniCPM4-0.5B-QAT-Int4-unquantized](https://huggingface.co/openbmb/MiniCPM4-0.5B-QAT-Int4-unquantized) | [MiniCPM4-0.5B-QAT-Int4-unquantized](https://modelscope.cn/models/OpenBMB/MiniCPM4-0.5B-QAT-Int4-unquantized) |
  | [MiniCPM4-0.5B-QAT-Int4-GPTQ-format](https://huggingface.co/openbmb/MiniCPM4-0.5B-QAT-Int4-GPTQ-format) | [MiniCPM4-0.5B-QAT-Int4-GPTQ-format](https://modelscope.cn/models/OpenBMB/MiniCPM4-0.5B-QAT-Int4-GPTQ-format) |
  | [MiniCPM3-4B](https://huggingface.co/openbmb/MiniCPM3-4B) | [MiniCPM3-4B](https://www.modelscope.cn/models/OpenBMB/MiniCPM3-4B) |
  | [MiniCPM-2B-sft](https://huggingface.co/openbmb/MiniCPM-2B-sft-bf16) | [MiniCPM-2B-sft](https://modelscope.cn/models/OpenBMB/miniCPM-bf16)|
  | [MiniCPM-2B-dpo](https://huggingface.co/openbmb/MiniCPM-2B-dpo-bf16) | [MiniCPM-2B-dpo](https://modelscope.cn/models/OpenBMB/MiniCPM-2B-dpo-bf16/summary) |
  | [MiniCPM-2B-128k](https://huggingface.co/openbmb/MiniCPM-2B-128k) | [MiniCPM-2B-128k](https://modelscope.cn/models/openbmb/MiniCPM-2B-128k/summary) |
  | [MiniCPM-MoE-8x2B](https://huggingface.co/openbmb/MiniCPM-MoE-8x2B) | [MiniCPM-MoE-8x2B](https://modelscope.cn/models/OpenBMB/MiniCPM-MoE-8x2B) |
  | [MiniCPM-1B](https://huggingface.co/openbmb/MiniCPM-1B-sft-bf16) | [MiniCPM-1B](https://modelscope.cn/models/OpenBMB/MiniCPM-1B-sft-bf16) |
  | [MiniCPM-S-1B](https://huggingface.co/openbmb/MiniCPM-S-1B-sft) | [MiniCPM-S-1B](https://modelscope.cn/models/OpenBMB/MiniCPM-S-1B-sft) |
</details>

## MiniCPM-SALA
#### äº®ç‚¹

MiniCPM-SALAï¼ˆç¨€ç–æ³¨æ„åŠ›ä¸çº¿æ€§æ³¨æ„åŠ›ï¼‰æ˜¯é¦–ä¸ªé«˜æ•ˆèåˆç¨€ç–ä¸çº¿æ€§æ³¨æ„åŠ›æœºåˆ¶ã€æ”¯æŒç™¾ä¸‡ä»¤ç‰Œä¸Šä¸‹æ–‡å»ºæ¨¡çš„å¤§è§„æ¨¡æ··åˆæ¨¡å‹

âœ… åˆ›æ–°æ··åˆæ¶æ„ï¼šèåˆ 25% ç¨€ç–æ³¨æ„åŠ›ï¼ˆInfLLM-v2ï¼‰å®ç°é«˜ç²¾åº¦é•¿æ–‡æœ¬å»ºæ¨¡ï¼Œæ­é… 75% çº¿æ€§æ³¨æ„åŠ›ï¼ˆLightning Attentionï¼‰ä¿éšœå…¨å±€å¤„ç†æ•ˆç‡ã€‚

âœ… çªç ´æ•ˆç‡å£å’ï¼šæ‰“ç ´â€œè®¡ç®—å¢™â€ä¸â€œå†…å­˜å¢™â€é™åˆ¶ï¼Œç›¸æ¯”å¯†é›†æ³¨æ„åŠ›åŸºçº¿å®ç° 3.5 å€æ¨ç†åŠ é€Ÿï¼Œå¹¶æ˜¾è‘—é™ä½KVç¼“å­˜å¼€é”€ã€‚

âœ… ç™¾ä¸‡ä»¤ç‰Œä¸Šä¸‹æ–‡ï¼šä¾æ‰˜é•¿ä¸Šä¸‹æ–‡æ„ŸçŸ¥ä½ç½®ç¼–ç æŠ€æœ¯ HyPEï¼Œå¯æ‰©å±•è‡³ 100 ä¸‡+ ä»¤ç‰Œå®¹é‡ï¼ŒåŒæ—¶ä¿æŒä¼˜å¼‚çš„é•¿æ–‡æœ¬æ³›åŒ–èƒ½åŠ›ã€‚

âœ… HALO é€‚åº”æœºåˆ¶ï¼šé‡‡ç”¨ HALO åˆ†å±‚ä¼˜åŒ–æ··åˆæ³¨æ„åŠ›æŠ€æœ¯ï¼Œé€šè¿‡åˆ›æ–°çš„è’¸é¦æ–¹æ¡ˆå°†å¯†é›†æ³¨æ„åŠ›èƒ½åŠ›æœ‰æ•ˆè¿ç§»è‡³æ··åˆæ¶æ„ï¼Œè§„é¿çº¯çº¿æ€§æ¨¡å‹å¸¸è§çš„ä¸¥é‡æ€§èƒ½è¡°å‡é—®é¢˜ã€‚

#### ç®€ä»‹

MiniCPM-SALA æ˜¯ä¸€ç§é«˜æ•ˆçš„æ··åˆæ¨¡å‹ï¼Œå…¶ä¸­ 25% çš„å±‚é‡‡ç”¨ [InfLLM-V2](https://arxiv.org/abs/2509.24663)ï¼Œå…¶ä½™ 75% ä½¿ç”¨ Lightning Attentionã€‚è¿™ç§æ¶æ„èƒ½åœ¨ NVIDIA RTX 5090 ç­‰æ¶ˆè´¹çº§ GPU ä¸Šè¿›è¡Œä¸€ç™¾ä¸‡ä»¤ç‰Œï¼ˆtokensï¼‰çš„æ¨ç†ã€‚

- **SALA æ··åˆæ³¨æ„åŠ›æœºåˆ¶**
  - æ•´åˆäº† 25% çš„ InfLLM-V2 å’Œ 75% çš„ Lightning Attentionï¼Œæœ‰æ•ˆåœ°åˆ©ç”¨äº†ç¨€ç–æ³¨æ„åŠ›å¯¹å±€éƒ¨ç»†èŠ‚çš„ç»†ç²’åº¦èšç„¦ï¼Œä»¥åŠçº¿æ€§æ³¨æ„åŠ›å¯¹å¹¿æ³›ä¸Šä¸‹æ–‡çš„é«˜æ•ˆç‡ã€‚

- **Transformer åˆ°æ··åˆæ¶æ„çš„æŒç»­è®­ç»ƒ**
  - é€šè¿‡å¯¹é¢„è®­ç»ƒæƒé‡è¿›è¡Œæ¶æ„è½¬æ¢ï¼Œè§„é¿äº†å†·å¯åŠ¨è®­ç»ƒçš„ä½æ•ˆæ€§ï¼Œä»è€Œå°†æ€»è®­ç»ƒé¢„ç®—é™è‡³ä»å¤´è®­ç»ƒåŒç±»æ¨¡å‹çš„çº¦ 25%ã€‚

- **[HyPE](https://arxiv.org/abs/2601.22156) (æ··åˆä½ç½®ç¼–ç )**
  - åè°ƒäº†çŸ­ä¸Šä¸‹æ–‡å’Œé•¿ä¸Šä¸‹æ–‡çš„æ€§èƒ½ï¼Œèƒ½å¤Ÿä¿æŒä¸ Qwen3-8B ç­‰ç°ä»£å…¨æ³¨æ„åŠ›æ¨¡å‹ç›¸å½“çš„é€šç”¨èƒ½åŠ›ï¼ˆå¦‚çŸ¥è¯†ã€æ•°å­¦å’Œç¼–ç¨‹ï¼‰ï¼Œå¹¶åœ¨å¤šä¸ªé•¿ä¸Šä¸‹æ–‡åŸºå‡†æµ‹è¯•ä¸­å–å¾—æ˜¾è‘—ä¼˜åŠ¿ã€‚

- **é•¿åºåˆ—çš„é«˜æ•ˆæ¨ç†**
  - åœ¨ NVIDIA A6000D ä¸Šã€åºåˆ—é•¿åº¦ä¸º 256K ä»¤ç‰Œæ—¶ï¼Œæ¨ç†é€Ÿåº¦è¾¾åˆ° Qwen3-8B çš„ 3.5 å€ï¼›æ”¯æŒåœ¨ NVIDIA A6000D å’Œ RTX 5090 GPU ä¸Šè¿›è¡Œé«˜è¾¾ 1M ä»¤ç‰Œçš„ä¸Šä¸‹æ–‡é•¿åº¦æ¨ç†ï¼Œè€Œ Qwen3-8B åœ¨æ­¤é•¿åº¦ä¸‹å› æ˜¾å­˜æº¢å‡ºï¼ˆOOMï¼‰è€Œå¤±è´¥ã€‚

### è¯„æµ‹ç»“æœ

#### æ•ˆç‡è¯„æµ‹

æˆ‘ä»¬é’ˆå¯¹ MiniCPM-SALA (9B) ä¸ Qwen3-8B åœ¨ NVIDIA A6000D å’Œ RTX 5090 GPU ä¸Šçš„è¡¨ç°è¿›è¡Œäº†æ¨ç†æ•ˆç‡æµ‹è¯•ã€‚MiniCPM-SALA ä¸ä»…åœ¨é¦–å­—å“åº”æ—¶é—´ï¼ˆTTFTï¼‰ä¸Šå®ç°äº†é«˜è¾¾ 2.5 å€çš„åŠ é€Ÿï¼Œè¿˜æˆåŠŸçªç ´äº†å…¨æ³¨æ„åŠ›æœºåˆ¶æ¶æ„çš„æ˜¾å­˜ç“¶é¢ˆã€‚åœ¨è¶…é•¿æ–‡æœ¬å¤„ç†ä¸­ï¼ŒQwen3-8B å› æ˜¾å­˜æº¢å‡ºï¼ˆOOMï¼‰è€Œå¤±è´¥ï¼Œè€Œ MiniCPM-SALA åˆ™èƒ½åœ¨å•å—æ¶ˆè´¹çº§ RTX 5090 æ˜¾å¡ä¸ŠæˆåŠŸå¤„ç†ä¸€ç™¾ä¸‡è¯å…ƒçš„ä¸Šä¸‹æ–‡ï¼Œæœ‰æœ›æ”¯æŒåœ¨è¾¹ç¼˜ç¡¬ä»¶ä¸Šè¿›è¡Œè¶…é•¿ä¸Šä¸‹æ–‡æ¨ç†ã€‚

![inference_speed_a6000d](./assets/minicpm_sala/inference_speed_a600d.png)

![inference_speed_5090](./assets/minicpm_sala/inference_speed_5090.png)

#### é•¿æ–‡æœ¬è¯„æµ‹

åœ¨å¤§å¤šæ•°é•¿ä¸Šä¸‹æ–‡åŸºå‡†æµ‹è¯•ä¸­ï¼ŒMiniCPM-SALA çš„è¡¨ç°å§‹ç»ˆä¼˜äºæ‰€æµ‹è¯•çš„å…¶ä»–åŒç­‰è§„æ¨¡çš„å¼€æºæ¨¡å‹ã€‚å…·ä½“è€Œè¨€ï¼ŒMiniCPM-SALA åœ¨ RULER å’Œ NoLiMa æµ‹è¯•çš„æ‰€æœ‰é•¿åº¦èŒƒå›´ï¼ˆæœ€é«˜ 128Kï¼‰å†…å‡å–å¾—äº†æœ€é«˜åˆ†ï¼Œå¹¶å–å¾—äº† 38.97 çš„æœ€é«˜ç»¼åˆå¹³å‡åˆ†ï¼Œè¡¨æ˜å…¶åœ¨é•¿æ–‡æœ¬ä¿¡æ¯å¤„ç†æ–¹é¢çš„å¼ºå¤§æ€§èƒ½ã€‚

![long_text_evaluation](./assets/minicpm_sala/long_text_evaluation.png)

#### è¶…é•¿æ–‡æœ¬è¯„æµ‹

MiniCPM-SALA å±•ç°å‡ºå‡ºè‰²çš„é•¿åº¦å¤–æ¨èƒ½åŠ›ã€‚å°½ç®¡å…¶è®­ç»ƒé•¿åº¦æœ€é•¿ä¸º 520K è¯å…ƒï¼Œä½†åœ¨ 2048K çš„ä¸Šä¸‹æ–‡é•¿åº¦ä¸‹ä»èƒ½ä¿æŒ 81.6 çš„é«˜åˆ†ã€‚è¯¥æ¨¡å‹æ— éœ€å€ŸåŠ© YaRN ç­‰è¾…åŠ©æŠ€æœ¯å³å¯å®ç°æœ‰æ•ˆå¤–æ¨ï¼Œè¿™å¯èƒ½å¾—ç›Šäºå…¶åœ¨ç¨€ç–æ³¨æ„åŠ›å±‚ä¸­é‡‡ç”¨çš„æ— ä½ç½®ç¼–ç ï¼ˆNoPEï¼‰é…ç½®ï¼Œæå‡äº†æ¨¡å‹é•¿è·ç¦»å»ºæ¨¡çš„èƒ½åŠ›ã€‚

![ultra_long_text_evaluation](./assets/minicpm_sala/ultra_long_text_evaluation.png)

#### ç»¼åˆè¯„æµ‹

MiniCPM-SALA åœ¨å¤šé¡¹æ ‡å‡†åŸºå‡†æµ‹è¯•ä¸­çš„å¹³å‡å¾—åˆ†ä¸º 76.53ï¼Œä¼˜äº Qwen3-8B å’Œ Falcon-H1R-7B ç­‰åŒç±»æ¨¡å‹ã€‚è¯¥æ¶æ„åœ¨å¸¸è¯†çŸ¥è¯†ã€ä»£ç ç”ŸæˆåŠæ•°å­¦é€»è¾‘ç­‰ç»´åº¦å‡ä¿æŒäº†ç¨³å¥çš„æ€§èƒ½è¡¨ç°ã€‚

![benchmark](./assets/minicpm_sala/benchmark.png)

### æ¨ç†

ä¸ºäº†è·å¾—æœ€ä½³æ€§èƒ½ï¼Œæˆ‘ä»¬å»ºè®®ä½¿ç”¨ `Temperature=0.9`ã€‚

#### HuggingFace

æˆ‘ä»¬çš„æ¨¡å‹ä¸ ğŸ¤— Hugging Face transformers å®Œå…¨å…¼å®¹ã€‚ä½ å¯ä»¥é€šè¿‡ä»¥ä¸‹ä»£ç è¿›è¡Œæ¨ç†ï¼š

```python
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

model_path = "openbmb/MiniCPM-SALA"
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True, device_map="auto")
model.eval()

prompts = ["My name is", "The capital of China is"]
with torch.no_grad():
    inputs = tokenizer(prompts, return_tensors="pt").to(model.device)
    outputs = model.generate(**inputs)
output_texts = tokenizer.batch_decode(outputs)
print(output_texts)
```

#### SGLang

##### ç¯å¢ƒè¦æ±‚

- CUDA 12.x æˆ–æ›´é«˜ç‰ˆæœ¬
- `gcc` / `g++` ç¼–è¯‘å™¨
- `uv` åŒ…ç®¡ç†å™¨ï¼ˆè„šæœ¬ä¼šè‡ªåŠ¨æ£€æµ‹ï¼‰

##### å®‰è£…

```bash
# å…‹éš†ä»“åº“
git clone -b minicpm_sala https://github.com/OpenBMB/sglang.git
cd sglang

# ä¸€é”®å®‰è£…ï¼ˆè‡ªåŠ¨åˆ›å»ºè™šæ‹Ÿç¯å¢ƒå¹¶ç¼–è¯‘æ‰€æœ‰ä¾èµ–ï¼‰
bash install_minicpm_sala.sh

# æˆ–æŒ‡å®š PyPI é•œåƒæº
bash install_minicpm_sala.sh https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple
```

å®‰è£…è„šæœ¬ä¼šè‡ªåŠ¨å®Œæˆä»¥ä¸‹æ­¥éª¤ï¼š

1. åˆ›å»º `sglang_minicpm_sala_env` è™šæ‹Ÿç¯å¢ƒï¼ˆPython 3.12ï¼‰
2. å…‹éš†ä¾èµ–åˆ° `3rdparty/` ç›®å½• (infllmv2) å¹¶åˆå§‹åŒ–å­æ¨¡å— (sparse_kernel)
3. å®‰è£… MiniCPM-SALA (å½“å‰ä»“åº“)
4. ç¼–è¯‘å®‰è£… `infllmv2_cuda_impl`
5. ç¼–è¯‘å®‰è£… `sparse_kernel`
6. å®‰è£… `tilelang` å’Œ `flash-linear-attention`

##### ä½¿ç”¨

```bash
# æ¿€æ´»ç¯å¢ƒ
source sglang_minicpm_sala_env/bin/activate

# å¯åŠ¨æ¨ç†æœåŠ¡ï¼ˆå°† MODEL_PATH æ›¿æ¢ä¸ºå®é™…æ¨¡å‹è·¯å¾„ï¼‰
MODEL_PATH=/path/to/your/model

python3 -m sglang.launch_server \
    --model ${MODEL_PATH} \
    --trust-remote-code \
    --disable-radix-cache \
    --attention-backend minicpm_flashinfer \
    --chunked-prefill-size 8192 \
    --max-running-requests 32 \
    --skip-server-warmup \
    --port 31111 \
    --dense-as-sparse
```

| å‚æ•° | è¯´æ˜ |
|------|------|
| `--trust-remote-code` | å…è®¸åŠ è½½æ¨¡å‹è‡ªå¸¦çš„è‡ªå®šä¹‰ä»£ç  |
| `--disable-radix-cache` | ç¦ç”¨ RadixAttention å‰ç¼€ç¼“å­˜ |
| `--attention-backend minicpm_flashinfer` | ä½¿ç”¨ MiniCPM FlashInfer æ³¨æ„åŠ›åç«¯ |
| `--chunked-prefill-size 8192` | chunked prefill å¤§å° |
| `--max-running-requests 32` | æœ€å¤§å¹¶å‘æ¨ç†è¯·æ±‚æ•° |
| `--skip-server-warmup` | è·³è¿‡æœåŠ¡é¢„çƒ­ |
| `--port 31111` | æœåŠ¡ç«¯å£ |
| `--dense-as-sparse` | ä½¿ç”¨ dense-as-sparse æ¨¡å¼ |

##### æ‰‹åŠ¨å®‰è£…

å¦‚æœä¸€é”®è„šæœ¬ä¸æ»¡è¶³éœ€æ±‚ï¼Œå¯ä»¥åˆ†æ­¥æ‰§è¡Œï¼š

```bash
# 0. ç¡®ä¿ uv å¯ç”¨
pip install uv

# 1. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
uv venv --python 3.12 sglang_minicpm_sala_env
source sglang_minicpm_sala_env/bin/activate

# 2. å®‰è£… SGLang
uv pip install --upgrade pip setuptools wheel
uv pip install -e ./python[all]

# 3. ç¼–è¯‘å®‰è£… CUDA æ‰©å±•
# (ç¡®ä¿ä¾èµ–å·²å…‹éš†åˆ° 3rdparty/ ç›®å½•)
cd 3rdparty/infllmv2_cuda_impl && python setup.py install && cd ../..
cd 3rdparty/sparse_kernel && python setup.py install && cd ../..

# 4. å®‰è£…é¢å¤–ä¾èµ–
uv pip install tilelang flash-linear-attention
```

##### Q&A

**Q: CUDA æ‰©å±•ç¼–è¯‘å¤±è´¥æ€ä¹ˆåŠï¼Ÿ**

- ç¡®ä¿ç³»ç»Ÿå®‰è£…äº† CUDA 12 ä»¥ä¸Šï¼ˆ`nvcc --version` æ£€æŸ¥ï¼‰ã€‚
- ç¡®ä¿ `gcc` / `g++` å¯ç”¨ã€‚
- å¦‚æœ `CXX` ç¯å¢ƒå˜é‡è¢«è®¾ä¸º `clang++ -pthread`ï¼Œæ‰‹åŠ¨ `export CXX=g++`ã€‚

## MiniCPM4 å’Œ MiniCPM4.1 ç³»åˆ—

<div align="center">
  <a href="https://www.youtube.com/watch?v=VouXjLHKDUY"><img src="https://img.youtube.com/vi/VouXjLHKDUY/0.jpg", width=70%></a>
</div>

#### äº®ç‚¹
MiniCPM4.1å…·æœ‰å¦‚ä¸‹äº®ç‚¹ï¼š

âœ… å¼ºå¤§çš„æ¨ç†èƒ½åŠ›ï¼šåœ¨15é¡¹ä»»åŠ¡ä¸­è¶…è¶ŠåŒç­‰è§„æ¨¡æ¨¡å‹ï¼

âœ… å¿«é€Ÿç”Ÿæˆï¼šç›¸æ¯”åŒç­‰è§„æ¨¡æ¨¡å‹ï¼Œæ¨ç†è§£ç é€Ÿåº¦æå‡3å€ï¼

âœ… é«˜æ•ˆæ¶æ„ï¼šä½¿ç”¨å¯è®­ç»ƒçš„ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ã€é«˜æ•ˆæŠ•æœºè§£ç åŠ é€Ÿç”Ÿæˆï¼

#### ç®€ä»‹
MiniCPM4 å’Œ MiniCPM4.1 ç³»åˆ—æ˜¯ä¸€ä¸ªæè‡´é«˜æ•ˆçš„ç«¯ä¾§å¤§æ¨¡å‹ï¼Œä»æ¨¡å‹æ¶æ„ã€å­¦ä¹ ç®—æ³•ã€è®­ç»ƒæ•°æ®ä¸æ¨ç†ç³»ç»Ÿå››ä¸ªå±‚é¢è¿›è¡Œäº†é«˜æ•ˆä¼˜åŒ–ï¼Œå®ç°äº†æè‡´çš„æ•ˆç‡æå‡ã€‚
- ğŸ—ï¸ é«˜æ•ˆæ¨¡å‹æ¶æ„ï¼š
  - InfLLM-V2 -- å¯è®­ç»ƒçš„ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ï¼šé‡‡ç”¨å¯è®­ç»ƒçš„ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶æ¶æ„ï¼Œåœ¨ 128K é•¿æ–‡æœ¬å¤„ç†ä¸­ï¼Œæ¯ä¸ªè¯å…ƒä»…éœ€ä¸ä¸è¶³ 5% çš„è¯å…ƒè¿›è¡Œç›¸å…³æ€§è®¡ç®—ï¼Œæ˜¾è‘—é™ä½é•¿æ–‡æœ¬çš„è®¡ç®—å¼€é”€ ï¼ˆ[è®­ç»ƒç®—å­](https://github.com/OpenBMB/infllmv2_cuda_impl)ï¼‰
- ğŸ§  é«˜æ•ˆå­¦ä¹ ç®—æ³•ï¼š
  - æ¨¡å‹é£æ´ 2.0 -- é«˜æ•ˆ Predictable Scalingï¼šå¼•å…¥ä¸‹æ¸¸ä»»åŠ¡çš„ Scaling é¢„æµ‹æ–¹æ³•ï¼Œå®ç°æ›´ç²¾å‡†çš„æ¨¡å‹è®­ç»ƒé…ç½®æœç´¢
  - BitCPM -- æè‡´çš„ä¸‰å€¼é‡åŒ–ï¼šå°†æ¨¡å‹å‚æ•°ä½å®½å‹ç¼©è‡³ 3 å€¼ï¼Œå®ç°æ¨¡å‹ä½å®½ 90% çš„æè‡´ç˜¦èº«
  - é«˜æ•ˆè®­ç»ƒå·¥ç¨‹ä¼˜åŒ–ï¼šé‡‡ç”¨ FP8 ä½ç²¾åº¦è®¡ç®—æŠ€æœ¯ï¼Œç»“åˆå¤šè¯å…ƒé¢„æµ‹ï¼ˆMulti-token Predictionï¼‰è®­ç»ƒç­–ç•¥
- ğŸ“š é«˜çŸ¥è¯†å¯†åº¦è®­ç»ƒæ•°æ®ï¼š
  - UltraClean -- é«˜è´¨é‡é¢„è®­ç»ƒæ•°æ®çš„æ¸…æ´—ä¸åˆæˆï¼šæ„å»ºåŸºäºé«˜æ•ˆéªŒè¯çš„è¿­ä»£å¼æ•°æ®æ¸…æ´—ç­–ç•¥ï¼Œå¼€æºé«˜è´¨é‡ä¸­è‹±æ–‡é¢„è®­ç»ƒæ•°æ®é›† [UltraFineweb](https://huggingface.co/datasets/openbmb/Ultra-FineWeb)
  - UltraChat v2 -- é«˜è´¨é‡æœ‰ç›‘ç£å¾®è°ƒæ•°æ®åˆæˆï¼šæ„å»ºå¤§è§„æ¨¡é«˜è´¨é‡æœ‰ç›‘ç£å¾®è°ƒæ•°æ®é›†ï¼Œæ¶µç›–çŸ¥è¯†å¯†é›†å‹æ•°æ®ã€æ¨ç†å¯†é›†å‹æ•°æ®ã€æŒ‡ä»¤éµå¾ªæ•°æ®ã€é•¿æ–‡æœ¬ç†è§£æ•°æ®ã€å·¥å…·è°ƒç”¨æ•°æ®ç­‰å¤šä¸ªç»´åº¦
- âš¡ é«˜æ•ˆæ¨ç†ç³»ç»Ÿï¼š
  - CPM.cu -- è½»é‡çº§çš„é«˜æ•ˆCUDAæ¨ç†æ¡†æ¶ï¼šèåˆäº†ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ã€æ¨¡å‹é‡åŒ–ä¸æŠ•æœºé‡‡æ ·ï¼Œå……åˆ†ä½“ç°MiniCPM4/MiniCPM4.1çš„æ•ˆç‡ä¼˜åŠ¿ ï¼ˆ[æ¨ç†ç®—å­ä¸æ¡†æ¶](https://github.com/openbmb/cpm.cu)ï¼‰
  - ArkInfer -- è·¨å¹³å°éƒ¨ç½²ç³»ç»Ÿï¼šæ”¯æŒå¤šåç«¯ç¯å¢ƒçš„ä¸€é”®éƒ¨ç½²ï¼Œæä¾›çµæ´»çš„è·¨å¹³å°é€‚é…èƒ½åŠ›

### è¯„æµ‹ç»“æœ
#### æ•ˆç‡è¯„æµ‹
åœ¨ Jetson AGX Orin å’Œ RTX 4090 ä¸¤æ¬¾å…¸å‹ç«¯ä¾§èŠ¯ç‰‡ä¸Šï¼ŒMiniCPM4 å’Œ MiniCPM4.1 åœ¨é•¿æ–‡æœ¬å¤„ç†ä»»åŠ¡ä¸­å±•ç°å‡ºå¤§å¹…é¢†å…ˆåŒå°ºå¯¸æ¨¡å‹çš„å¤„ç†é€Ÿåº¦ã€‚éšç€æ–‡æœ¬é•¿åº¦çš„å¢åŠ ï¼ŒMiniCPM4 å’Œ MiniCPM4.1 çš„æ€§èƒ½ä¼˜åŠ¿æ„ˆå‘æ˜¾è‘—ã€‚åœ¨ Jetson AGX Orin å¹³å°ä¸Šï¼Œç›¸è¾ƒäº Qwen3-8Bï¼ŒMiniCPM4 å®ç°äº†çº¦ 7 å€çš„ç”Ÿæˆé€Ÿåº¦æå‡ã€‚

![benchmark](./assets/minicpm4/efficiency.png)

MiniCPM4.1 åœ¨æ¨ç†é€Ÿåº¦ä¸Šå®ç°äº† 3 å€çš„ç”Ÿæˆé€Ÿåº¦æå‡ã€‚

![benchmark](./assets/minicpm4/minicpm4.1_speed.png)

#### ç»¼åˆè¯„æµ‹
MiniCPM4.1 æ¨å‡ºç«¯ä¾§ 8B å‚æ•°è§„æ¨¡ç‰ˆæœ¬ï¼Œæ·±æ€è€ƒæ¨¡å¼åœ¨åŒçº§åˆ«æ¨¡å‹ä¸­å®ç°äº†æœ€ä½³æ€§èƒ½è¡¨ç°ã€‚
![benchmark](./assets/minicpm4/benchmark4.1.png)

MiniCPM4 æ¨å‡ºç«¯ä¾§ 8Bã€0.5B ä¸¤ç§å‚æ•°è§„æ¨¡ç‰ˆæœ¬ï¼Œå‡åœ¨åŒçº§åˆ«æ¨¡å‹ä¸­å®ç°äº†æœ€ä½³æ€§èƒ½è¡¨ç°ã€‚
![benchmark](./assets/minicpm4/benchmark.png)


#### é•¿æ–‡æœ¬è¯„æµ‹
MiniCPM4 åŸºäº 32K é•¿æ–‡æœ¬è¿›è¡Œé¢„è®­ç»ƒï¼Œå¹¶é€šè¿‡ YaRN æŠ€æœ¯å®ç°é•¿åº¦æ‰©å±•ã€‚åœ¨ 128K é•¿æ–‡æœ¬çš„å¤§æµ·æé’ˆä»»åŠ¡ä¸­ï¼ŒMiniCPM4 å±•ç°å‡ºå“è¶Šçš„æ€§èƒ½è¡¨ç°ã€‚MiniCPM4.1 åŸºäº 64K é•¿æ–‡æœ¬è¿›è¡Œé¢„è®­ç»ƒï¼Œå¹¶é€šè¿‡ YaRN æŠ€æœ¯å®ç°é•¿åº¦æ‰©å±•ã€‚åœ¨ 128K é•¿æ–‡æœ¬çš„å¤§æµ·æé’ˆä»»åŠ¡ä¸­ï¼ŒMiniCPM4.1 å±•ç°å‡ºå“è¶Šçš„æ€§èƒ½è¡¨ç°ã€‚

![long-niah](./assets/minicpm4/128k-niah.png)


### æ¨¡å‹æ¨ç†
ä½ å¯ä»¥ä½¿ç”¨Huggingface Transformersã€vLLMã€SGLangã€CPM.cuå¯¹æ¨¡å‹è¿›è¡Œæ¨ç†ã€‚å¦‚æœæƒ³è¦ä½“éªŒæè‡´çš„æ•ˆç‡ä¼˜åŒ–ï¼Œæˆ‘ä»¬æ¨èä½¿ç”¨CPM.cuã€‚

MiniCPM4/MiniCPM4.1 æ”¯æŒç¨ å¯†æ¨ç†ä¸ç¨€ç–æ¨ç†ä¸¤ç§æ¨¡å¼ï¼Œå…¶ä¸­vLLMä¸SGLangç›®å‰åªæ”¯æŒäº†ç¨ å¯†æ¨ç†æ¨¡å¼ã€‚å¦‚æœæƒ³è¦ä½¿ç”¨ç¨€ç–æ¨ç†æ¨¡å¼ï¼Œè¯·ä½¿ç”¨Huggingface TransformersåŠCPM.cuã€‚

- ç¨ å¯†æ³¨æ„åŠ›æ¨ç†ï¼švLLMã€SGLangã€Huggingface Transformers
- ç¨€ç–æ³¨æ„åŠ›æ¨ç†ï¼šHuggingface Transformersã€CPM.cu


#### æ··åˆæ€è€ƒ

MiniCPM4.1 æ”¯æŒæ··åˆæ€è€ƒæ¨¡å¼ï¼Œå¯ä»¥ç”¨äºæ·±åº¦æ€è€ƒå’Œéæ€è€ƒæ¨¡å¼ã€‚ç”¨æˆ·å¯ä»¥é€šè¿‡è®¾ç½® `enable_thinking=True` æ¥å¯ç”¨æ··åˆæ€è€ƒæ¨¡å¼ï¼Œè®¾ç½® `enable_thinking=False` æ¥å¯ç”¨éæ€è€ƒæ¨¡å¼ã€‚åŒæ ·ï¼Œç”¨æˆ·å¯ä»¥ç›´æ¥åœ¨æŸ¥è¯¢æœ«å°¾æ·»åŠ  `/no_think` æ¥å¯ç”¨éæ€è€ƒæ¨¡å¼ã€‚å¦‚æœæœªæ·»åŠ ä»»ä½•ç‰¹æ®Šæ ‡è®°æˆ–åœ¨æŸ¥è¯¢æœ«å°¾æ·»åŠ  `/think`ï¼Œæ¨¡å‹å°†å¯ç”¨æ€è€ƒæ¨¡å¼ã€‚

```python
# Enable reasoning mode
prompt_text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True,
    enable_thinking=True
)
# Enable non-reasoning mode
prompt_text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True,
    enable_thinking=False
)
```



#### HuggingFace

- **ç¨ å¯†æ³¨æ„åŠ›æ¨ç†**
```python
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch
torch.manual_seed(0)

path = 'openbmb/MiniCPM4.1-8B'
device = "cuda"
tokenizer = AutoTokenizer.from_pretrained(path)
model = AutoModelForCausalLM.from_pretrained(path, torch_dtype=torch.bfloat16, device_map=device, trust_remote_code=True)

# User can directly use the chat interface
# responds, history = model.chat(tokenizer, "Write an article about Artificial Intelligence.", temperature=0.7, top_p=0.7)
# print(responds)

# User can also use the generate interface
messages = [
    {"role": "user", "content": "Write an article about Artificial Intelligence."},
]
prompt_text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True,
)
model_inputs = tokenizer([prompt_text], return_tensors="pt").to(device)

model_outputs = model.generate(
    **model_inputs,
    max_new_tokens=32768,
    top_p=0.95,
    temperature=0.6
)
output_token_ids = [
    model_outputs[i][len(model_inputs[i]):] for i in range(len(model_inputs['input_ids']))
]

responses = tokenizer.batch_decode(output_token_ids, skip_special_tokens=True)[0]
print(responses)
```

- **ç¨€ç–æ³¨æ„åŠ›æ¨ç†**
æœ¬æ¨¡å‹æ”¯æŒç¨€ç–æ³¨æ„åŠ›æœºåˆ¶ InfLLM v2ï¼Œå¯é«˜æ•ˆå¤„ç†é•¿åºåˆ—æ¨ç†ã€‚å¦‚éœ€å¯ç”¨è¯¥åŠŸèƒ½ï¼Œè¯·å…ˆå®‰è£…ä¾èµ–åº“ [infllmv2_cuda_impl](https://github.com/OpenBMB/infllmv2_cuda_impl)


è¿è¡Œä»¥ä¸‹å‘½ä»¤å³å¯å®‰è£…ï¼š

```bash
git clone -b feature_infer https://github.com/OpenBMB/infllmv2_cuda_impl.git
cd infllmv2_cuda_impl
git submodule update --init --recursive
pip install -e . # or python setup.py install 
```

å¯ç”¨ InfLLM v2 éœ€åœ¨ `config.json` é…ç½®æ–‡ä»¶ä¸­æ·»åŠ  `sparse_config` å­—æ®µï¼š

```json
{
    ...,
    "sparse_config": {
        "kernel_size": 32,
        "kernel_stride": 16,
        "init_blocks": 1,
        "block_size": 64,
        "window_size": 2048,
        "topk": 64,
        "use_nope": false,
        "dense_len": 8192
    }
}
```

è¿™äº›å‚æ•°æ§åˆ¶ InfLLM v2 çš„è¡Œä¸º:

* `kernel_size`ï¼ˆé»˜è®¤å€¼ï¼š32ï¼‰ï¼šè¯­ä¹‰æ ¸çš„å¤§å°ã€‚  
* `kernel_stride`ï¼ˆé»˜è®¤å€¼ï¼š16ï¼‰ï¼šç›¸é‚»è¯­ä¹‰æ ¸çš„æ­¥é•¿ã€‚  
* `init_blocks`ï¼ˆé»˜è®¤å€¼ï¼š1ï¼‰ï¼šæ¯ä¸ª query token å…³æ³¨çš„åˆå§‹çš„å—æ•°é‡ï¼Œç”¨äºç¡®ä¿å…³æ³¨åºåˆ—å¼€å¤´éƒ¨åˆ†ã€‚  
* `block_size`ï¼ˆé»˜è®¤å€¼ï¼š64ï¼‰ï¼škey-value blocks çš„å—å¤§å°ã€‚  
* `window_size`ï¼ˆé»˜è®¤å€¼ï¼š2048ï¼‰ï¼šå±€éƒ¨æ»‘åŠ¨çª—å£å¤§å°ã€‚  
* `topk`ï¼ˆé»˜è®¤å€¼ï¼š64ï¼‰ï¼šæ¯ä¸ª token ä»…ä¸æœ€ç›¸å…³çš„ top-k ä¸ª key-value blocks è®¡ç®—æ³¨æ„åŠ›ã€‚  
* `use_nope`ï¼ˆé»˜è®¤å€¼ï¼šfalseï¼‰ï¼šæ˜¯å¦åœ¨å—é€‰æ‹©ä¸­ä½¿ç”¨NOPEæŠ€æœ¯ä»¥æå‡æ€§èƒ½ã€‚  
* `dense_len`ï¼ˆé»˜è®¤å€¼ï¼š8192ï¼‰ï¼šç¨€ç–æ³¨æ„åŠ›å¯¹çŸ­åºåˆ—æ”¶ç›Šæœ‰é™ï¼Œå½“ token é•¿åº¦ä½äºæ­¤é˜ˆå€¼æ—¶è‡ªåŠ¨åˆ‡æ¢ä¸ºæ ‡å‡†æ³¨æ„åŠ›ã€‚è®¾ä¸º `-1` åˆ™å¼ºåˆ¶å§‹ç»ˆä½¿ç”¨ç¨€ç–æ³¨æ„åŠ›ã€‚

- **é•¿åº¦æ‰©å±•**
Minicpm4.1 åŸç”Ÿæ”¯æŒ 65,536 tokens çš„ä¸Šä¸‹æ–‡é•¿åº¦ã€‚è‹¥å¯¹è¯æ€»é•¿åº¦ï¼ˆè¾“å…¥ + è¾“å‡ºï¼‰è¿œè¶…æ­¤é™åˆ¶ï¼Œå»ºè®®é€šè¿‡ RoPE ç¼©æ”¾æŠ€æœ¯æ‰©å±•ä¸Šä¸‹æ–‡ã€‚æˆ‘ä»¬å·²éªŒè¯é€šè¿‡è°ƒæ•´ LongRoPE å› å­ï¼Œæ¨¡å‹å¯ç¨³å®šæ”¯æŒ 131,072 tokens çš„è¶…é•¿ä¸Šä¸‹æ–‡ã€‚

ä¿®æ”¹æ–¹æ³•ï¼šåœ¨ `config.json` æ–‡ä»¶ä¸­è°ƒæ•´ `rope_scaling` å­—æ®µå‚æ•°å³å¯ã€‚

```json
{
    ...,
    "rope_scaling": {
        "rope_type": "longrope", 
        "long_factor": [0.9982316082870437, 1.033048153422584, 1.0749920956484724, 1.1255096879436193, 1.1863348602111476, 1.259543828902579, 1.3476188888731149, 1.4535223827776373, 1.5807816745852985, 1.7335856049489526, 1.9168922912975785, 2.1365471404135326, 2.3994084200118646, 2.713475511863602, 3.0880118452194134, 3.533650295140154, 4.062463396503134, 4.687974098908333, 5.425075306704039, 6.289818967956352, 7.29902962722721, 8.6357018163639, 10.210822723989212, 12.053807765671676, 14.193944598909404, 16.65780676784363, 19.463620727694074, 22.628311203524586, 26.150106147261315, 30.02526691405111, 34.23183327975347, 38.73811934094828, 43.502489489729555, 48.47627117965394, 53.61139491762471, 58.857366522037935, 64.16798299215064, 69.51359464319125, 74.86555458220285, 80.21497790341579, 85.55322183307433, 90.89611806932027, 96.26245306514224, 101.68269304046481, 107.18619510219668, 112.82253283014026, 118.63764063163615, 119.88866203644656, 120.9462882391725, 121.837565139014, 122.58663780572562, 123.2147719894291, 123.74049454862576, 124.17980424685767, 124.54641761955492, 124.85202548028222, 125.10654406389756, 125.31835105170659, 125.49450117164764, 125.64091910903052, 125.76256945356558, 125.86360463815589, 125.94749252260765, 126.01712561287873],
        "short_factor": [0.9982316082870437, 1.033048153422584, 1.0749920956484724, 1.1255096879436193, 1.1863348602111476, 1.259543828902579, 1.3476188888731149, 1.4535223827776373, 1.5807816745852985, 1.7335856049489526, 1.9168922912975785, 2.1365471404135326, 2.3994084200118646, 2.713475511863602, 3.0880118452194134, 3.533650295140154, 4.062463396503134, 4.687974098908333, 5.425075306704039, 6.289818967956352, 7.29902962722721, 8.6357018163639, 10.210822723989212, 12.053807765671676, 14.193944598909404, 16.65780676784363, 19.463620727694074, 22.628311203524586, 26.150106147261315, 30.02526691405111, 34.23183327975347, 38.73811934094828, 43.502489489729555, 48.47627117965394, 53.61139491762471, 58.857366522037935, 64.16798299215064, 69.51359464319125, 74.86555458220285, 80.21497790341579, 85.55322183307433, 90.89611806932027, 96.26245306514224, 101.68269304046481, 107.18619510219668, 112.82253283014026, 118.63764063163615, 119.88866203644656, 120.9462882391725, 121.837565139014, 122.58663780572562, 123.2147719894291, 123.74049454862576, 124.17980424685767, 124.54641761955492, 124.85202548028222, 125.10654406389756, 125.31835105170659, 125.49450117164764, 125.64091910903052, 125.76256945356558, 125.86360463815589, 125.94749252260765, 126.01712561287873],
        "original_max_position_embeddings": 65536
    }
}
```

#### vLLM

ä½ å¯ä»¥ä½¿ç”¨æŠ•æœºé‡‡æ ·åŠ é€Ÿæ¨¡å‹ç”Ÿæˆï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨æ ‡å‡†æ¨¡å¼éƒ¨ç½²æ¨¡å‹ã€‚
##### æŠ•æœºé‡‡æ ·

ä½¿ç”¨ vLLM è¿›è¡ŒåŠ é€Ÿæ¨ç†çš„æŠ•æœºé‡‡æ ·æ­¥éª¤å¦‚ä¸‹ï¼š

###### 1. ä¸‹è½½ MiniCPM4.1 è‰ç¨¿æ¨¡å‹

é¦–å…ˆï¼Œä¸‹è½½ MiniCPM4.1 è‰ç¨¿æ¨¡å‹ï¼š

```bash
cd /your_path
git clone https://huggingface.co/openbmb/MiniCPM4.1-8B-Eagle3
```

###### 2. å®‰è£… EAGLE3 å…¼å®¹çš„ vLLM

EAGLE3 çš„ vLLM PR å·²ç»æäº¤ã€‚ç›®å‰è¯·ä½¿ç”¨æˆ‘ä»¬çš„ä»“åº“è¿›è¡Œå®‰è£…ï¼š

```bash
git clone https://github.com/LDLINGLINGLING/vllm.git
cd vllm 
pip install -e .
```

###### 3. å¯åŠ¨å¸¦æœ‰æŠ•æœºé‡‡æ ·çš„ vLLM æœåŠ¡

å¯åŠ¨å¯ç”¨äº†æŠ•æœºé‡‡æ ·çš„ vLLM æ¨ç†æœåŠ¡ã€‚è¯·ç¡®ä¿åœ¨ speculative-config ä¸­å°†æ¨¡å‹è·¯å¾„æ›´æ–°ä¸ºä¸‹è½½çš„ MiniCPM4_1-8B-Eagle3-bf16 æ–‡ä»¶å¤¹ï¼š

```bash
VLLM_USE_V1=1 \
vllm serve openbmb/MiniCPM4.1-8B \
--seed 42 \
--trust-remote-code \
--speculative-config '{
  "model": "your/path/MiniCPM4_1-8B-Eagle3-bf16",
  "num_speculative_tokens": 3,
  "method": "eagle3",
  "draft_tensor_parallel_size": 1
}'
```

###### 4. å®¢æˆ·ç«¯ä½¿ç”¨ç¤ºä¾‹

å®¢æˆ·ç«¯ä½¿ç”¨æ–¹å¼åœ¨æ ‡å‡†è§£ç å’ŒæŠ•æœºé‡‡æ ·ä¸‹ä¿æŒä¸€è‡´ï¼š

```python
import openai

client = openai.Client(base_url="http://localhost:8000/v1", api_key="EMPTY")

response = client.chat.completions.create(
    model="openbmb/MiniCPM4.1-8B",
    messages=[
        {"role": "user", "content": "Write an article about Artificial Intelligence."},
    ],
    temperature=0.6,
    max_tokens=32768,
    extra_body=dict(add_special_tokens=True),  # ç¡®ä¿åœ¨èŠå¤©æ¨¡æ¿ä¸­åŠ å…¥ç‰¹æ®Šç¬¦å·
    
)

print(response.choices[0].message.content)
```

###### vLLM é…ç½®å‚æ•°è¯´æ˜

-	`VLLM_USE_V1=1`: å¯ç”¨ vLLM v1 API
-	`--speculative-config`: æŠ•æœºé‡‡æ ·çš„ JSON é…ç½®
  -	`model`: è‰ç¨¿æ¨¡å‹çš„è·¯å¾„
  -	`num_speculative_tokens`: æ¨æµ‹çš„ token æ•°é‡ï¼ˆé»˜è®¤ï¼š3ï¼‰
  -	`method`: æŠ•æœºé‡‡æ ·æ–¹æ³•ï¼ˆeagle3ï¼‰
  -	`draft_tensor_parallel_size`: è‰ç¨¿æ¨¡å‹çš„å¼ é‡å¹¶è¡Œå¤§å°ï¼ˆé»˜è®¤ï¼š1ï¼‰
-	`--seed`: éšæœºç§å­ï¼Œç”¨äºå¯å¤ç°æ€§
-	`--trust-remote-code`: å…è®¸æ‰§è¡Œè¿œç¨‹ä»£ç ä»¥æ”¯æŒè‡ªå®šä¹‰æ¨¡å‹

##### æ ‡å‡†æ¨ç†ï¼ˆä¸ä½¿ç”¨æŠ•æœºé‡‡æ ·ï¼‰

ç›®å‰ä½ éœ€è¦å®‰è£…æœ€æ–°ç‰ˆæœ¬çš„ vLLMã€‚

```bash
pip install -U vllm \
    --pre \
    --extra-index-url https://wheels.vllm.ai/nightly
```

ç„¶åå¯ä»¥ç”¨ vLLM æ¨ç† MiniCPM4.1-8Bï¼š

```python
from transformers import AutoTokenizer
from vllm import LLM, SamplingParams

model_name = "openbmb/MiniCPM4.1-8B"
prompt = [{"role": "user", "content": "Write an article about Artificial Intelligence."}]

tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)
input_text = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)

llm = LLM(
    model=model_name,
    trust_remote_code=True,
    max_num_batched_tokens=65536,
    dtype="bfloat16", 
    gpu_memory_utilization=0.8, 
)
sampling_params = SamplingParams(top_p=0.95, temperature=0.6, max_tokens=32768)

outputs = llm.generate(prompts=input_text, sampling_params=sampling_params)

print(outputs[0].outputs[0].text)
```

ä½ ä¹Ÿå¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤å¯åŠ¨æ¨ç†æœåŠ¡ï¼š

> æ³¨æ„: åœ¨ vLLM çš„ chat API ä¸­ï¼Œadd_special_tokens é»˜è®¤æ˜¯ Falseã€‚è¿™æ„å‘³ç€é‡è¦çš„ç‰¹æ®Šç¬¦å·â€”â€”æ¯”å¦‚åºåˆ—å¼€å§‹ç¬¦ï¼ˆBOS tokenï¼‰â€”â€”ä¸ä¼šè¢«è‡ªåŠ¨åŠ å…¥ã€‚ä¸ºäº†ç¡®ä¿è¾“å…¥æç¤ºå¯¹æ¨¡å‹æ ¼å¼æ­£ç¡®ï¼Œå»ºè®®æ˜¾å¼è®¾ç½® extra_body={"add_special_tokens": True}ã€‚

```bash
vllm serve openbmb/MiniCPM4.1-8B --trust-remote-code
```

ç„¶åå¯ä»¥é€šè¿‡ä»¥ä¸‹ä»£ç ä½¿ç”¨èŠå¤©æ¥å£ï¼š

```python
import openai

client = openai.Client(base_url="http://localhost:8000/v1", api_key="EMPTY")

response = client.chat.completions.create(
    model="openbmb/MiniCPM4.1-8B",
    messages=[
        {"role": "user", "content": "Write an article about Artificial Intelligence."},
    ],
    temperature=0.6,
    max_tokens=32768,
    extra_body=dict(add_special_tokens=True),  # ç¡®ä¿åœ¨èŠå¤©æ¨¡æ¿ä¸­åŠ å…¥ç‰¹æ®Šç¬¦å·
)

print(response.choices[0].message.content)
```

#### SGLang

ä½ å¯ä»¥ä½¿ç”¨æŠ•æœºé‡‡æ ·åŠ é€Ÿæ¨¡å‹ç”Ÿæˆï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨æ ‡å‡†æ¨¡å¼éƒ¨ç½²æ¨¡å‹ã€‚

##### æŠ•æœºé‡‡æ ·

ä½¿ç”¨æŠ•æœºé‡‡æ ·è¿›è¡ŒåŠ é€Ÿæ¨ç†çš„æ­¥éª¤å¦‚ä¸‹ï¼š

###### 1. ä¸‹è½½ MiniCPM4.1 è‰ç¨¿æ¨¡å‹

é¦–å…ˆï¼Œä¸‹è½½ MiniCPM4.1 è‰ç¨¿æ¨¡å‹ï¼š

```bash
cd /your_path
git clone https://huggingface.co/openbmb/MiniCPM4.1-8B-Eagle3
```

###### 2. å®‰è£… EAGLE3 å…¼å®¹çš„ SGLang

EAGLE3 çš„é€‚é… PR å·²ç»æäº¤ã€‚ç›®å‰è¯·ä½¿ç”¨æˆ‘ä»¬çš„ä»“åº“è¿›è¡Œå®‰è£…ï¼š

```bash
git clone https://github.com/LDLINGLINGLING/sglang.git
cd sglang
pip install -e .
```

###### 3. å¯åŠ¨å¸¦æœ‰æŠ•æœºé‡‡æ ·çš„ SGLang æœåŠ¡

å¯åŠ¨å¯ç”¨äº†æŠ•æœºé‡‡æ ·çš„ SGLang æœåŠ¡ï¼š

```bash
python -m sglang.launch_server \
  --model-path "openbmb/MiniCPM4.1-8B" \
  --host "127.0.0.1" \
  --port 30002 \
  --mem-fraction-static 0.9 \
  --speculative-algorithm EAGLE3 \
  --speculative-draft-model-path "your/path/MiniCPM4_1-8B-Eagle3-bf16" \
  --speculative-num-steps 3 \
  --speculative-eagle-topk 1 \
  --speculative-num-draft-tokens 32 \
  --temperature 0.7
```

###### 4. å®¢æˆ·ç«¯ä½¿ç”¨

å®¢æˆ·ç«¯ä½¿ç”¨æ–¹å¼åœ¨æ ‡å‡†è§£ç å’ŒæŠ•æœºé‡‡æ ·ä¸‹ä¿æŒä¸€è‡´ï¼š

```python
import openai

client = openai.Client(base_url=f"http://localhost:30002/v1", api_key="None")

response = client.chat.completions.create(
    model="openbmb/MiniCPM4.1-8B",
    messages=[
        {"role": "user", "content": "Write an article about Artificial Intelligence."},
    ],
    temperature=0.6,
    max_tokens=32768,
)

print(response.choices[0].message.content)
```

> æ³¨æ„ï¼šè¯·ç¡®ä¿åœ¨å®¢æˆ·ç«¯ä»£ç ä¸­æ›´æ–°ç«¯å£å·ï¼Œä»¥åŒ¹é…æœåŠ¡ç«¯ç«¯å£ï¼ˆåœ¨æŠ•æœºé‡‡æ ·ç¤ºä¾‹ä¸­ä¸º 30002ï¼‰ã€‚

###### é…ç½®å‚æ•°è¯´æ˜
-	`--speculative-algorithm EAGLE3`: å¯ç”¨ EAGLE3 æŠ•æœºé‡‡æ ·
-	`--speculative-draft-model-path`: è‰ç¨¿æ¨¡å‹è·¯å¾„
-	`--speculative-num-steps`: æ¨æµ‹æ­¥æ•°ï¼ˆé»˜è®¤ï¼š3ï¼‰
-	`--speculative-eagle-topk`: EAGLE çš„ top-k å‚æ•°ï¼ˆé»˜è®¤ï¼š1ï¼‰
-	`--speculative-num-draft-tokens`: è‰ç¨¿ token æ•°é‡ï¼ˆé»˜è®¤ï¼š32ï¼‰
-	`--mem-fraction-static`: é™æ€åˆ†é…çš„æ˜¾å­˜æ¯”ä¾‹ï¼ˆé»˜è®¤ï¼š0.9ï¼‰

##### æ ‡å‡†æ¨ç†ï¼ˆä¸ä½¿ç”¨æŠ•æœºé‡‡æ ·ï¼‰

ç›®å‰ä½ éœ€è¦å®‰è£…æˆ‘ä»¬ fork çš„ SGLang ç‰ˆæœ¬ã€‚

```bash
git clone -b openbmb https://github.com/OpenBMB/sglang.git
cd sglang

pip install --upgrade pip
pip install -e "python[all]"
```

ä½ å¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤å¯åŠ¨æ¨ç†æœåŠ¡ï¼š

```bash
python -m sglang.launch_server --model openbmb/MiniCPM4.1-8B --trust-remote-code --port 30000 --chat-template chatml
```

ç„¶åå¯ä»¥é€šè¿‡ä»¥ä¸‹ä»£ç ä½¿ç”¨èŠå¤©æ¥å£ï¼š

```python
import openai

client = openai.Client(base_url=f"http://localhost:30000/v1", api_key="None")

response = client.chat.completions.create(
    model="openbmb/MiniCPM4.1-8B",
    messages=[
        {"role": "user", "content": "Write an article about Artificial Intelligence."},
    ],
    temperature=0.6,
    max_tokens=32768,
)

print(response.choices[0].message.content)
```


#### CPM.cu

æˆ‘ä»¬**æ¨è**ä½¿ç”¨ [CPM.cu](https://github.com/OpenBMB/CPM.cu) å¯¹ MiniCPM4 å’Œ MiniCPM4.1 æ¨¡å‹è¿›è¡Œæ¨ç†ã€‚CPM.cu æ˜¯é¢å£å¼€å‘çš„ä¸€ä¸ªé›†åˆäº†é«˜æ•ˆç¨€ç–ã€æŠ•æœºé‡‡æ ·ã€é‡åŒ–ç­‰æŠ€æœ¯çš„ CUDA æ¨ç†æ¡†æ¶ï¼Œèƒ½å¤Ÿå®Œå…¨å‘æŒ¥ MiniCPM4 å’Œ MiniCPM4.1 çš„æ•ˆç‡ä¼˜åŠ¿ã€‚

ä½ å¯ä»¥é€šè¿‡ä»¥ä¸‹è„šæœ¬å®‰è£… CPM.cu å¹¶è¿›è¡Œæ¨ç†ï¼š

```bash
git clone https://github.com/OpenBMB/CPM.cu.git --recursive
cd CPM.cu
python3 setup.py install
```

ä½ å¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤è¿›è¡Œæ¨ç†å¹¶æŸ¥çœ‹æ¨¡å‹çš„è¿è¡Œé€Ÿåº¦ã€‚

```bash
python3 tests/long_prompt_gen.py # ç”Ÿæˆ prompt.txt
python3 tests/test_generate.py --prompt-file prompt.txt
```

ä½ å¯ä»¥é€šè¿‡ä¸€ä¸‹å‘½ä»¤ä½¿ç”¨ EAGLE3 è¿›è¡ŒæŠ•æœºæ¨ç†ã€‚

```bash
python3 -m cpmcu.cli \
    --model-path $BASE_MODEL_PATH \
    --draft-model-path $EAGLE3_DRAFT_MODEL_PATH \
    --prompt-text "Tell me about Tsinghua University" \
    --use-eagle3 true
```

æ›´å¤šå…³äº CPM.cu çš„ç»†èŠ‚ï¼Œè¯·å‚è€ƒ [CPM.cu ä»“åº“](https://github.com/OpenBMB/CPM.cu)ã€‚


#### llama.cpp and Ollama

æˆ‘ä»¬åŒæ ·æ”¯æŒä½¿ç”¨ [llama.cpp](https://github.com/ggml-org/llama.cpp) å’Œ [Ollama](https://ollama.com/) è¿›è¡Œæ¨¡å‹æ¨ç†ã€‚

#### llama.cpp

ä½ å¯ä»¥ä» [huggingface](https://huggingface.co/openbmb/MiniCPM4.1-8B-GGUF) ä¸‹è½½ MiniCPM4.1-8B çš„ GGUF æ ¼å¼æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨ llama.cpp è¿›è¡Œæ¨ç†ã€‚
```
# case 1: main-cli
./build/bin/llama-cli -m MiniCPM4.1-8B-Q4_K_M.gguf -p "Write an article about Artificial 
Intelligence." -n 1500

# case 2: server
## launch server
./build/bin/llama-server -m MiniCPM4.1-8B-Q4_K_M.gguf --host 127.0.0.1 --port 8080 -c 
4096 -fa on &

## send request
curl -X POST http://127.0.0.1:8080/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-3.5-turbo",
    "messages": [{"role": "user", "content": "Write an article about Artificial 
    Intelligence."}],
    "max_tokens": 1500
  }'
```

#### Ollama
è¯·å‰å¾€ [æ¨¡å‹åº“](https://ollama.com/openbmb/minicpm4.1) ä¸‹è½½æ¨¡å‹ã€‚å®‰è£…å¥½ Ollama åï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤ä½¿ç”¨ MiniCPM4.1ï¼š
```
ollama run openbmb/minicpm4.1
```

### æ¨¡å‹å¾®è°ƒ
#### LLaMA-Factory
ç›®å‰æ¨¡å‹å¾®è°ƒæ”¯æŒ [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory)ï¼Œä½¿ç”¨æ–¹æ³•å‚è€ƒ [LLaMA-Factory å¾®è°ƒ](https://t0mvtyikswc.feishu.cn/docx/Gv6ld1yCTodckBxysKgcpepJnKg?from=from_copylink)

### BitCPM4: æ¨¡å‹é‡åŒ–
BitCPM4 æ˜¯åŸºäº MiniCPM ç³»åˆ—æ¨¡å‹è¿›è¡Œé‡åŒ–æ„ŸçŸ¥è®­ç»ƒï¼ˆQATï¼‰åå¾—åˆ°çš„ä¸‰å€¼é‡åŒ–æ¨¡å‹ï¼Œåœ¨è®­ç»ƒæ•ˆç‡å’Œæ¨¡å‹å‚æ•°æ•ˆç‡å®ç°äº†æœ‰æ•ˆçš„æå‡ã€‚
- è®­ç»ƒæ–¹æ³•æ”¹è¿›
  - åœ¨å°è§„æ¨¡æ¨¡å‹ä¸Šè¿›è¡Œé£æ´å®éªŒï¼Œæœç´¢è®­ç»ƒæ‰€éœ€çš„è®­ç»ƒè¶…å‚ã€‚
  - é€šè¿‡ä½¿ç”¨ä¸€é˜¶æ®µé«˜ç²¾è®­ç»ƒ+äºŒé˜¶æ®µ QAT çš„æ–¹æ³•ï¼Œå……åˆ†åˆ©ç”¨å·²ç»å®Œæˆæˆ–éƒ¨åˆ†å®Œæˆè®­ç»ƒçš„é«˜ç²¾åº¦æ¨¡å‹ï¼Œæå¤§åœ°å‹ç¼©äº† QAT é˜¶æ®µæ‰€éœ€è¦çš„ç®—åŠ›ã€‚
- é«˜æ•ˆå‚æ•°æ•ˆç‡
  - æ¨¡å‹ä½¿ç”¨ 1.58Bit çš„ä½å®½è¾¾åˆ°çš„æ€§èƒ½å¯¹æ ‡ä¸åŒå‚æ•°é‡çº§åˆ«çš„å…¨ç²¾åº¦æ¨¡å‹ï¼Œæ¨¡å‹å‚æ•°æ•ˆç‡é«˜ã€‚

#### BitCPM4 è¯„æµ‹
BitCPM4 åœ¨æµ‹è¯•ä¸­çš„è¡¨ç°å¯ä»¥å¯¹æ ‡åŒçº§åˆ«çš„ä¸šç•Œä¸»æµå…¨ç²¾åº¦æ¨¡å‹ã€‚
![bitcpm-benchmark](./assets/minicpm4/bitcpm4-benchmark.png)

#### BitCPM4 æ¨¡å‹æ¨ç†
BitCPM4 å¼€æºçš„æ¨¡å‹å‚æ•°ä¸ºä¼ªé‡åŒ–å½¢å¼ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ Huggingface æ¡†æ¶è¿›è¡Œæ¨ç†ã€‚

### æ¨¡å‹åº”ç”¨
<details>
<summary>æŸ¥çœ‹ MiniCPM4 çš„åº”ç”¨</summary>
#### MiniCPM4-Survey: ç»¼è¿°ç”Ÿæˆ
MiniCPM4-Survey æ˜¯ç”± [THUNLP](https://nlp.csai.tsinghua.edu.cn)ã€ä¸­å›½äººæ°‘å¤§å­¦å’Œ [ModelBest](https://modelbest.cn/en) è”åˆå¼€å‘çš„å¼€æºå¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“ã€‚å®ƒåŸºäº MiniCPM4-8B åŸºåº§æ¨¡å‹ï¼Œæ¥å—ç”¨æˆ·è´¨é‡ä½œä¸ºè¾“å…¥ï¼Œè‡ªä¸»ç”Ÿæˆå¯ä¿¡çš„é•¿ç¯‡ç»¼è¿°è®ºæ–‡ã€‚
ä¸»è¦ç‰¹æ€§åŒ…æ‹¬ï¼š
- è®¡åˆ’-æ£€ç´¢-å†™ä½œç”Ÿæˆæ¡†æ¶ â€” æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªå¤šæ™ºèƒ½ä½“ç”Ÿæˆæ¡†æ¶ï¼ŒåŒ…å«ä¸‰ä¸ªæ ¸å¿ƒé˜¶æ®µï¼šè®¡åˆ’ï¼ˆå®šä¹‰ç»¼è¿°çš„æ•´ä½“ç»“æ„ï¼‰ã€æ£€ç´¢ï¼ˆç”Ÿæˆåˆé€‚çš„æ£€ç´¢å…³é”®è¯ï¼‰å’Œå†™ä½œï¼ˆåˆ©ç”¨æ£€ç´¢åˆ°çš„ä¿¡æ¯ï¼Œç”Ÿæˆè¿è´¯çš„æ®µè½ï¼‰ã€‚
- é«˜è´¨é‡æ•°æ®é›†æ„å»ºâ€”â€”æˆ‘ä»¬æ”¶é›†å¹¶å¤„ç†å¤§é‡äººç±»ä¸“å®¶å†™ä½œçš„ç»¼è¿°è®ºæ–‡ï¼Œæ„å»ºé«˜è´¨é‡è®­ç»ƒé›†ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬æ”¶é›†å¤§é‡ç ”ç©¶è®ºæ–‡ï¼Œæ„å»ºæ£€ç´¢æ•°æ®åº“ã€‚
- å¤šæ–¹é¢å¥–åŠ±è®¾è®¡ â€” æˆ‘ä»¬ç²¾å¿ƒè®¾è®¡äº†åŒ…å«ç»“æ„ã€å†…å®¹å’Œå¼•ç”¨çš„å¥–åŠ±ï¼Œç”¨äºè¯„ä¼°ç»¼è¿°çš„è´¨é‡ï¼Œåœ¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒé˜¶æ®µä½œå¥–åŠ±å‡½æ•°ã€‚
- å¤šæ­¥å¼ºåŒ–å­¦ä¹ è®­ç»ƒç­–ç•¥ â€” æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œä»¥ç¡®ä¿åœ¨ä¿ƒè¿›æœ‰æ•ˆæ¨ç†çš„åŒæ—¶ä¿ç•™å¿…è¦çš„ä¿¡æ¯ï¼Œå¹¶æ„å»ºäº†å¹¶è¡Œç¯å¢ƒï¼Œç»´æŒå¼ºåŒ–å­¦ä¹ è®­ç»ƒé«˜æ•ˆã€‚
##### ä½¿ç”¨ä¸æ¼”ç¤ºæ¡ˆä¾‹

è¯¦è§[æ­¤å¤„](./demo/minicpm4/SurveyGeneration/README.md)

##### è¯„ä¼°

| Method                                      | Relevance | Coverage | Depth | Novelty | Avg.  | Fact Score |
|---------------------------------------------|-----------|----------|-------|---------|-------|------------|
| Naive RAG (driven by G2FT)                  | 3.25      | 2.95     | 3.35  | 2.60    | 3.04  | 43.68      |
| AutoSurvey (driven by G2FT)                 | 3.10      | 3.25     | 3.15  | **3.15**| 3.16  | 46.56      |
| Webthinker (driven by WTR1-7B)              | 3.30      | 3.00     | 2.75  | 2.50    | 2.89  | --         |
| Webthinker (driven by QwQ-32B)              | 3.40      | 3.30     | 3.30  | 2.50    | 3.13  | --         |
| OpenAI Deep Research (driven by GPT-4o)     | 3.50      |**3.95**  | 3.55  | 3.00    | **3.50**  | --         |
| MiniCPM4-Survey                            | 3.45      | 3.70     | **3.85** | 3.00    | **3.50**  | **68.73**  |
| &nbsp;&nbsp;&nbsp;*w/o* RL                  | **3.55**  | 3.35     | 3.30  | 2.25    | 3.11  | 50.24      |

*GPT-4o å¯¹ç»¼è¿°ç”Ÿæˆç³»ç»Ÿçš„æ€§èƒ½æ¯”è¾ƒã€‚â€œG2FTâ€ ä»£è¡¨ Gemini-2.0-Flash-Thinkingï¼Œâ€œWTR1-7Bâ€ ä»£è¡¨ Webthinker-R1-7Bã€‚ç”±äº Webthinker ä¸åŒ…æ‹¬å¼•ç”¨åŠŸèƒ½ï¼ŒOpenAI Deep Research åœ¨å¯¼å‡ºç»“æœæ—¶ä¸æä¾›å¼•ç”¨ï¼Œå› æ­¤çœç•¥äº†å¯¹å®ƒä»¬çš„ FactScore è¯„ä¼°ã€‚æˆ‘ä»¬çš„æŠ€æœ¯æŠ¥å‘Šä¸­åŒ…å«è¯„æµ‹çš„è¯¦ç»†ä¿¡æ¯ã€‚*

#### MiniCPM4-MCP: MCPå¢å¼ºçš„å·¥å…·è°ƒç”¨

MiniCPM4-MCP æ˜¯ç”±[æ¸…åå¤§å­¦è‡ªç„¶è¯­è¨€å¤„ç†å®éªŒå®¤ï¼ˆTHUNLPï¼‰](https://nlp.csai.tsinghua.edu.cn)ã€ä¸­å›½äººæ°‘å¤§å­¦ä¸ [ModelBest](https://modelbest.cn/en) è”åˆå¼€å‘çš„å¼€æºæœ¬åœ°å¤§è¯­è¨€æ¨¡å‹ä»£ç†ï¼Œå®ƒåŸºäº MiniCPM-4-8Bï¼Œæ‹¥æœ‰ 80 äº¿å‚æ•°ã€‚å®ƒèƒ½å¤Ÿé€šè¿‡ MCP åè®®ä¸å„ç§å·¥å…·å’Œæ•°æ®èµ„æºäº¤äº’ï¼Œè§£å†³å¤šç§çœŸå®ä¸–ç•Œä»»åŠ¡ã€‚æˆªè‡³ç›®å‰ï¼ŒMiniCPM4-MCP å·²æ”¯æŒï¼š

- æ¶µç›– 16 ä¸ª MCP æœåŠ¡å™¨ï¼ˆserversï¼‰ä¸­å·¥å…·çš„ä½¿ç”¨ï¼šè¿™äº›æœåŠ¡å™¨æ‰€åŒ…å«çš„å·¥å…·æ¨ªè·¨äº†åŠå…¬ç±»ã€ç”Ÿæ´»ç±»ã€é€šè®¯ç±»ã€èµ„è®¯ç±»ã€å·¥ä½œç®¡ç†ç±»ç­‰.

- å•å·¥å…·ä½¿ç”¨çš„èƒ½åŠ›ï¼šå¯ä½¿ç”¨ç¬¦åˆ MCP åè®®çš„å·¥å…·è¿›è¡Œå•ä¸€å·¥å…·çš„ä¸€æ­¥æˆ–å¤šæ­¥è°ƒç”¨ã€‚

- è·¨å·¥å…·ç»„åˆä½¿ç”¨çš„èƒ½åŠ›ï¼šå¯ç»„åˆä½¿ç”¨ç¬¦åˆ MCP åè®®çš„ä¸åŒå·¥å…·ã€‚


##### ä½¿ç”¨ä¸æ¼”ç¤ºæ¡ˆä¾‹

è¯¦è§[æ­¤å¤„](./demo/minicpm4/MCP/README.md)

##### è¯„ä¼°

| MCP æœåŠ¡å™¨             |          | gpt-4o   |          |          | qwen3    |          |          | minicpm4 |          |
| -------------------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- | -------- |
|                      | å‡½æ•°åæ­£ç¡®ç‡   | å‚æ•°åæ­£ç¡®ç‡    | æ•°å€¼æ­£ç¡®ç‡    | å‡½æ•°åæ­£ç¡®ç‡   | å‚æ•°åæ­£ç¡®ç‡    | æ•°å€¼æ­£ç¡®ç‡    | å‡½æ•°åæ­£ç¡®ç‡   | å‚æ•°åæ­£ç¡®ç‡    | æ•°å€¼æ­£ç¡®ç‡    |
| Airbnb                | 89.3           | 67.9         | 53.6         | 92.8          | 60.7         | 50.0         | 96.4           | 67.9         | 50.0         |
| Amap-Maps             | 79.8           | 77.5         | 50.0         | 74.4          | 72.0         | 41.0         | 89.3           | 85.7         | 39.9         |
| Arxiv-MCP-Server      | 85.7           | 85.7         | 85.7         | 81.8          | 54.5         | 50.0         | 57.1           | 57.1         | 52.4         |
| Calculator            | 100.0          | 100.0        | 20.0         | 80.0          | 80.0         | 13.3         | 100.0          | 100.0        | 6.67         |
| Computor-Control-MCP  | 90.0           | 90.0         | 90.0         | 90.0          | 90.0         | 90.0         | 90.0           | 90.0         | 86.7         |
| Desktop-Commander     | 100.0          | 100.0        | 100.0        | 100.0         | 100.0        | 100.0        | 100.0          | 100.0        | 100.0        |
| Filesystem            | 63.5           | 63.5         | 31.3         | 69.7          | 69.7         | 26.0         | 83.3           | 83.3         | 42.7         |
|Github | 92.0 | 80.0 | 58.0 | 80.5 | 50.0 | 27.7 | 62.8 | 25.7 | 17.1 |
| Gaode                 | 71.1           | 55.6         | 17.8         | 68.8          | 46.6         | 24.4         | 68.9           | 46.7         | 15.6         |
| MCP-Code-Executor     | 85.0           | 80.0         | 70.0         | 80.0          | 80.0         | 70.0         | 90.0           | 90.0         | 65.0         |
| MCP-Docx              | 95.8           | 86.7         | 67.1         | 94.9          | 81.6         | 60.1         | 95.1           | 86.6         | 76.1         |
| PPT                   | 72.6           | 49.8         | 40.9         | 85.9          | 50.7         | 37.5         | 91.2           | 72.1         | 56.7         |
| PPTx                  | 64.2           | 53.7         | 13.4         | 91.0          | 68.6         | 20.9         | 91.0           | 58.2         | 26.9         |
| Simple-Time-Server    | 90.0           | 70.0         | 70.0         | 90.0          | 90.0         | 90.0         | 90.0           | 60.0         | 60.0         |
| Slack                 | 100.0          | 90.0         | 70.0         | 100.0         | 100.0        | 65.0         | 100.0          | 100.0        | 100.0        |
| Whisper               | 90.0           | 90.0         | 90.0         | 90.0          | 90.0         | 90.0         | 90.0           | 90.0         | 30.0         |
| **å¹³å‡å€¼**              | **80.2**       | **70.2**     | **49.1**     | **83.5**      | **67.7**     | **43.8**     | **88.3**       | **76.1**     | **51.2**     |

#### MiniCPM Intel AIPC Client: ç«¯ä¾§å¤§æ¨¡å‹å®¢æˆ·ç«¯

MiniCPM Intel AIPC Client æ˜¯é¢å£æ™ºèƒ½å’Œ Intel åˆä½œæ¨å‡ºçš„ç«¯ä¾§å¤§æ¨¡å‹å®¢æˆ·ç«¯ï¼Œä¸“ä¸ºæ­è½½ Intel Core Ultra ç³»åˆ—å¤„ç†å™¨çš„è®¾å¤‡è®¾è®¡ï¼Œæ—¨åœ¨ä¸ºå¼€å‘è€…ã€ç ”ç©¶äººå‘˜ä¸ AI çˆ±å¥½è€…å¸¦æ¥ä½å»¶è¿Ÿã€é«˜æ•ˆç‡ã€é«˜éšç§çš„æœ¬åœ°å¤§æ¨¡å‹ä½¿ç”¨ä½“éªŒã€‚å…¶æ ¸å¿ƒç‰¹æ€§å¦‚ä¸‹ï¼š

- æ·±åº¦é€‚é… Intel ç¡¬ä»¶ï¼šå…¨é¢æ”¯æŒ Intel Core Ultra ç³»åˆ—å¤„ç†å™¨ï¼Œå®ç°ä¸ç¡¬ä»¶çš„æ·±åº¦èåˆï¼Œå……åˆ†é‡Šæ”¾ç¡¬ä»¶æ€§èƒ½ï¼Œè®©ç”¨æˆ·æ— éœ€ä¾èµ–äº‘ç«¯ï¼Œåœ¨æœ¬åœ°è®¾å¤‡ä¸Šå°±èƒ½æµç•…è¿è¡Œå¤§æ¨¡å‹ã€‚
- åŸºäº OpenVINO çš„æè‡´ä¼˜åŒ–ï¼šåŸºäº OpenVINO æ¨ç†æ¡†æ¶è¿›è¡Œæ·±åº¦ä¼˜åŒ–ï¼Œå¤§å¹…æå‡æ¨ç†æ•ˆç‡ï¼Œæ¨ç†é€Ÿåº¦æœ€é«˜å¯è¾¾æ¯ç§’ 80 tokensï¼Œç¡®ä¿æ¨¡å‹å“åº”è¿…é€Ÿï¼Œæ— è®ºæ˜¯å¿«é€Ÿé—®ç­”è¿˜æ˜¯å¤æ‚ä»»åŠ¡å¤„ç†ï¼Œéƒ½èƒ½é«˜æ•ˆå®Œæˆã€‚
- éšç§å®‰å…¨ä¿éšœï¼šé‡‡ç”¨æœ¬åœ°éƒ¨ç½²æ–¹å¼ï¼Œæ‰€æœ‰æ•°æ®å¤„ç†å‡åœ¨æœ¬åœ°è®¾å¤‡å®Œæˆï¼Œé¿å…æ•°æ®ä¸Šä¼ è‡³äº‘ç«¯å¸¦æ¥çš„éšç§é£é™©ï¼Œè®©ç”¨æˆ·ä½¿ç”¨æ›´å®‰å¿ƒï¼Œå°¤å…¶é€‚åˆå¯¹æ•°æ®éšç§è¦æ±‚è¾ƒé«˜çš„åœºæ™¯ã€‚
- é¢å‘å¤šå…ƒç”¨æˆ·ç¾¤ä½“ï¼šæ— è®ºæ˜¯è¿½æ±‚å‰æ²¿æŠ€æœ¯çš„å¼€å‘è€…ï¼Œä¸“æ³¨å­¦æœ¯ç ”ç©¶çš„ç§‘ç ”äººå‘˜ï¼Œè¿˜æ˜¯çƒ­è¡·äºæ¢ç´¢ AI åº”ç”¨çš„çˆ±å¥½è€…ï¼Œéƒ½èƒ½é€šè¿‡ MiniCPM Intel AIPC Clientï¼Œè½»æ¾ä½“éªŒæœ¬åœ°å¤§æ¨¡å‹çš„å¼ºå¤§åŠŸèƒ½ï¼Œå¼€å¯ä¸ªæ€§åŒ–çš„ AI æ¢ç´¢ä¹‹æ—… ã€‚

é…ç½®è¦æ±‚ï¼š

- å»ºè®®ä½¿ç”¨è‹±ç‰¹å°”é…·ç¿ ultra7 åŠä»¥ä¸Šç§»åŠ¨ç«¯å¤„ç†å™¨
- å»ºè®®è¿è¡Œå†…å­˜ 32GB åŠä»¥ä¸Š  

åº”ç”¨ä¸‹è½½ï¼š

[ä¸‹è½½åœ°å€](https://github.com/OpenBMB/MiniCPM/releases/tag/2.4.2)
</details>


## å¼€æºåè®®

#### æ¨¡å‹åè®®

* æœ¬ä»“åº“ä¸­ä»£ç ä¸ MiniCPM æ¨¡å‹æƒé‡ä¾ç…§ [Apache-2.0](https://github.com/OpenBMB/MiniCPM/blob/main/LICENSE) åè®®å¼€æº

#### å£°æ˜

* ä½œä¸ºä¸€ä¸ªè¯­è¨€æ¨¡å‹ï¼ŒMiniCPM é€šè¿‡å­¦ä¹ å¤§é‡çš„æ–‡æœ¬æ¥ç”Ÿæˆå†…å®¹ï¼Œä½†å®ƒæ— æ³•ç†è§£ã€è¡¨è¾¾ä¸ªäººè§‚ç‚¹æˆ–ä»·å€¼åˆ¤æ–­ï¼Œå®ƒæ‰€è¾“å‡ºçš„ä»»ä½•å†…å®¹éƒ½ä¸ä»£è¡¨æ¨¡å‹å¼€å‘è€…çš„è§‚ç‚¹å’Œç«‹åœºã€‚
* å› æ­¤ç”¨æˆ·åœ¨ä½¿ç”¨ MiniCPM ç”Ÿæˆçš„å†…å®¹æ—¶ï¼Œåº”è‡ªè¡Œè´Ÿè´£å¯¹å…¶è¿›è¡Œè¯„ä¼°å’ŒéªŒè¯ã€‚
* å¦‚æœç”±äºä½¿ç”¨ MiniCPM å¼€æºæ¨¡å‹è€Œå¯¼è‡´çš„ä»»ä½•é—®é¢˜ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºæ•°æ®å®‰å…¨é—®é¢˜ã€å…¬å…±èˆ†è®ºé£é™©ï¼Œæˆ–æ¨¡å‹è¢«è¯¯å¯¼ã€æ»¥ç”¨ã€ä¼ æ’­æˆ–ä¸å½“åˆ©ç”¨æ‰€å¸¦æ¥çš„ä»»ä½•é£é™©å’Œé—®é¢˜ï¼Œæˆ‘ä»¬å°†ä¸æ‰¿æ‹…ä»»ä½•è´£ä»»ã€‚

## å¼€å‘æœºæ„

æœ¬é¡¹ç›®ç”±ä»¥ä¸‹æœºæ„å…±åŒå¼€å‘ï¼š

- <img src="assets/modelbest.png" width="28px"> [é¢å£æ™ºèƒ½](https://modelbest.cn/)
- <img src="assets/thunlp.png" width="28px"> [æ¸…åå¤§å­¦è‡ªç„¶è¯­è¨€å¤„ç†å®éªŒå®¤](https://nlp.csai.tsinghua.edu.cn/)
- <img src="assets/RUC.png" width="28px"> [äººå¤§é«˜ç“´äººå·¥æ™ºèƒ½å­¦é™¢](https://linyankai.github.io/)

## å·¥ä½œå¼•ç”¨

* å¦‚æœè§‰å¾— MiniCPM æœ‰åŠ©äºæ‚¨çš„å·¥ä½œï¼Œè¯·å¼•ç”¨æˆ‘ä»¬çš„è®ºæ–‡ï¼š[MiniCPM4](https://arxiv.org/abs/2506.07900)

```
@article{minicpm4,
  title={Minicpm4: Ultra-efficient llms on end devices},
  author={MiniCPM, Team},
  journal={arXiv preprint arXiv:2506.07900},
  year={2025}
}
```
